 INFO [2017-07-29 05:47:10,838] ({Thread-0} RemoteInterpreterServer.java[run]:97) - Starting remote interpreter server on port 39039
 INFO [2017-07-29 05:47:11,132] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2017-07-29 05:47:11,153] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2017-07-29 05:47:11,161] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2017-07-29 05:47:11,180] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2017-07-29 05:47:11,185] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2017-07-29 05:47:11,247] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307231246 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:47:13,958] ({pool-2-thread-4} SparkInterpreter.java[createSparkSession]:318) - ------ Create new SparkContext local[*] -------
 WARN [2017-07-29 05:47:13,961] ({pool-2-thread-4} SparkInterpreter.java[setupConfForSparkR]:562) - sparkr.zip is not found, sparkr may not work.
 INFO [2017-07-29 05:47:14,667] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Running Spark version 2.1.0
 WARN [2017-07-29 05:47:14,945] ({pool-2-thread-4} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 WARN [2017-07-29 05:47:15,007] ({pool-2-thread-4} Logging.scala[logWarning]:66) - 
SPARK_CLASSPATH was detected (set to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
 WARN [2017-07-29 05:47:15,010] ({pool-2-thread-4} Logging.scala[logWarning]:66) - Setting 'spark.executor.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 WARN [2017-07-29 05:47:15,011] ({pool-2-thread-4} Logging.scala[logWarning]:66) - Setting 'spark.driver.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 INFO [2017-07-29 05:47:15,046] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2017-07-29 05:47:15,048] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2017-07-29 05:47:15,051] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2017-07-29 05:47:15,052] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2017-07-29 05:47:15,053] ({pool-2-thread-4} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2017-07-29 05:47:15,334] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 39355.
 INFO [2017-07-29 05:47:15,367] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2017-07-29 05:47:15,396] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2017-07-29 05:47:15,400] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2017-07-29 05:47:15,400] ({pool-2-thread-4} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2017-07-29 05:47:15,411] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-911edfe9-e153-4dea-9e27-c50e9445dbec
 INFO [2017-07-29 05:47:15,421] ({pool-2-thread-4} Logging.scala[logInfo]:54) - MemoryStore started with capacity 408.9 MB
 INFO [2017-07-29 05:47:15,473] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2017-07-29 05:47:15,546] ({pool-2-thread-4} Log.java[initialized]:186) - Logging initialized @5112ms
 INFO [2017-07-29 05:47:15,653] ({pool-2-thread-4} Server.java[doStart]:327) - jetty-9.2.z-SNAPSHOT
 INFO [2017-07-29 05:47:15,683] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@27a54740{/jobs,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,684] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@a797e24{/jobs/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,684] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3deec29c{/jobs/job,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,685] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@10a757b0{/jobs/job/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,686] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1d358da3{/stages,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,686] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5c7c587f{/stages/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,687] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@174d9b4e{/stages/stage,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,688] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3d7d54c0{/stages/stage/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,690] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@c949e59{/stages/pool,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,691] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@32159014{/stages/pool/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,698] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@49f9faf3{/storage,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,698] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1ef56c58{/storage/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,699] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@36bb5f89{/storage/rdd,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,700] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2830fc7a{/storage/rdd/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,700] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2e18b5ed{/environment,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,701] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1b3a8bda{/environment/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,702] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7791c823{/executors,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,702] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@58ed3987{/executors/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,703] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@33b148aa{/executors/threadDump,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,704] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7c9a715d{/executors/threadDump/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,714] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5b37e3d{/static,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,715] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@34234e0d{/,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,717] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@d6ea43b{/api,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,718] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@22d13c52{/jobs/job/kill,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,719] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3c8deca3{/stages/stage/kill,null,AVAILABLE}
 INFO [2017-07-29 05:47:15,732] ({pool-2-thread-4} AbstractConnector.java[doStart]:266) - Started ServerConnector@6e2c2e50{HTTP/1.1}{0.0.0.0:4040}
 INFO [2017-07-29 05:47:15,733] ({pool-2-thread-4} Server.java[doStart]:379) - Started @5298ms
 INFO [2017-07-29 05:47:15,733] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2017-07-29 05:47:15,735] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040
 INFO [2017-07-29 05:47:15,844] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/pyspark.zip at file:/zeppelin/interpreter/spark/pyspark/pyspark.zip with timestamp 1501307235844
 INFO [2017-07-29 05:47:15,847] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/pyspark.zip to /tmp/spark-9bd4517c-1e58-43c0-8640-37cf750c10ce/userFiles-51288966-330e-4f9e-8fb7-d25fc9c8a421/pyspark.zip
 INFO [2017-07-29 05:47:15,867] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip at file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip with timestamp 1501307235867
 INFO [2017-07-29 05:47:15,868] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip to /tmp/spark-9bd4517c-1e58-43c0-8640-37cf750c10ce/userFiles-51288966-330e-4f9e-8fb7-d25fc9c8a421/py4j-0.10.4-src.zip
 INFO [2017-07-29 05:47:15,921] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
 INFO [2017-07-29 05:47:15,951] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting executor ID driver on host localhost
 INFO [2017-07-29 05:47:15,956] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using REPL class URI: spark://172.17.0.2:39355/classes
 INFO [2017-07-29 05:47:15,989] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43997.
 INFO [2017-07-29 05:47:15,991] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Server created on 172.17.0.2:43997
 INFO [2017-07-29 05:47:15,993] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2017-07-29 05:47:15,994] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, 172.17.0.2, 43997, None)
 INFO [2017-07-29 05:47:15,997] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.17.0.2:43997 with 408.9 MB RAM, BlockManagerId(driver, 172.17.0.2, 43997, None)
 INFO [2017-07-29 05:47:16,001] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, 172.17.0.2, 43997, None)
 INFO [2017-07-29 05:47:16,002] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, 172.17.0.2, 43997, None)
 INFO [2017-07-29 05:47:16,161] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7dbcbd15{/metrics/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,194] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Warehouse path is 'file:/zeppelin/spark-warehouse'.
 INFO [2017-07-29 05:47:16,205] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@29332090{/SQL,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,206] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1f85d9b{/SQL/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,208] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7c26433{/SQL/execution,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,210] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@79ed97c9{/SQL/execution/json,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,212] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@4baf0ccd{/static/sql,null,AVAILABLE}
 INFO [2017-07-29 05:47:16,248] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
 INFO [2017-07-29 05:47:16,809] ({pool-2-thread-4} HiveMetaStore.java[newRawStore]:589) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
 INFO [2017-07-29 05:47:16,831] ({pool-2-thread-4} ObjectStore.java[initialize]:289) - ObjectStore, initialize called
 INFO [2017-07-29 05:47:16,999] ({pool-2-thread-4} Log4JLogger.java[info]:77) - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
 INFO [2017-07-29 05:47:17,000] ({pool-2-thread-4} Log4JLogger.java[info]:77) - Property datanucleus.cache.level2 unknown - will be ignored
 INFO [2017-07-29 05:47:19,186] ({pool-2-thread-4} ObjectStore.java[getPMF]:370) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
 INFO [2017-07-29 05:47:19,866] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2017-07-29 05:47:19,867] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2017-07-29 05:47:20,940] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2017-07-29 05:47:20,942] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2017-07-29 05:47:21,215] ({pool-2-thread-4} MetaStoreDirectSql.java[<init>]:139) - Using direct SQL, underlying DB is DERBY
 INFO [2017-07-29 05:47:21,219] ({pool-2-thread-4} ObjectStore.java[setConf]:272) - Initialized ObjectStore
 WARN [2017-07-29 05:47:21,325] ({pool-2-thread-4} ObjectStore.java[checkSchema]:6666) - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
 WARN [2017-07-29 05:47:21,449] ({pool-2-thread-4} ObjectStore.java[getDatabase]:568) - Failed to get database default, returning NoSuchObjectException
 INFO [2017-07-29 05:47:21,571] ({pool-2-thread-4} HiveMetaStore.java[createDefaultRoles_core]:663) - Added admin role in metastore
 INFO [2017-07-29 05:47:21,577] ({pool-2-thread-4} HiveMetaStore.java[createDefaultRoles_core]:672) - Added public role in metastore
 INFO [2017-07-29 05:47:21,674] ({pool-2-thread-4} HiveMetaStore.java[addAdminUsers_core]:712) - No user is added in admin role, since config is empty
 INFO [2017-07-29 05:47:21,769] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_all_databases
 INFO [2017-07-29 05:47:21,771] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_all_databases	
 INFO [2017-07-29 05:47:21,791] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_functions: db=default pat=*
 INFO [2017-07-29 05:47:21,792] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
 INFO [2017-07-29 05:47:21,795] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2017-07-29 05:47:21,941] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root
 INFO [2017-07-29 05:47:21,946] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created local directory: /tmp/root
 INFO [2017-07-29 05:47:21,952] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created local directory: /tmp/1573248a-f1d9-4f67-8d94-571c5725acc4_resources
 INFO [2017-07-29 05:47:21,958] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/1573248a-f1d9-4f67-8d94-571c5725acc4
 INFO [2017-07-29 05:47:21,964] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created local directory: /tmp/root/1573248a-f1d9-4f67-8d94-571c5725acc4
 INFO [2017-07-29 05:47:21,982] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/1573248a-f1d9-4f67-8d94-571c5725acc4/_tmp_space.db
 INFO [2017-07-29 05:47:21,985] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Warehouse location for Hive client (version 1.2.1) is file:/zeppelin/spark-warehouse
 INFO [2017-07-29 05:47:21,994] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_database: default
 INFO [2017-07-29 05:47:21,995] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
 INFO [2017-07-29 05:47:22,017] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_database: global_temp
 INFO [2017-07-29 05:47:22,018] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: global_temp	
 WARN [2017-07-29 05:47:22,019] ({pool-2-thread-4} ObjectStore.java[getDatabase]:568) - Failed to get database global_temp, returning NoSuchObjectException
 INFO [2017-07-29 05:47:22,021] ({pool-2-thread-4} SparkInterpreter.java[createSparkSession]:362) - Created Spark session with Hive support
 INFO [2017-07-29 05:47:27,350] ({pool-2-thread-4} SparkInterpreter.java[populateSparkWebUrl]:997) - Sending metainfos to Zeppelin server: {url=http://172.17.0.2:4040}
 INFO [2017-07-29 05:47:28,112] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307231246 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:48:12,835] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307292833 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:48:13,346] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307292833 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:48:45,976] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307325976 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:48:48,022] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307325976 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:48:56,934] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307336933 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:49:08,683] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307336933 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:18,197] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307478196 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:18,200] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307478196 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:41,935] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307501931 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:41,939] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307501931 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:45,182] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307505180 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:45,185] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307505180 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:53,864] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307513863 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:53,869] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307513863 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:55,534] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307515533 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:55,536] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307515533 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:56,226] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307516225 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:56,234] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307516225 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:56,842] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307516841 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:56,848] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307516841 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:59,786] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307519786 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:51:59,790] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307519786 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:16,506] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307536505 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:16,915] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307536505 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:28,244] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307548244 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:28,598] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307548244 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:50,030] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1501307570028 started by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:52:50,393] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1501307570028 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter645661357
 INFO [2017-07-29 05:53:59,511] ({pool-1-thread-4} InterpreterGroup.java[close]:151) - Close interpreter group 2CP2FWSDN:shared_process
 INFO [2017-07-29 05:53:59,512] ({Thread-43} SparkInterpreter.java[close]:1385) - Close interpreter
 INFO [2017-07-29 05:53:59,520] ({Thread-43} AbstractConnector.java[doStop]:306) - Stopped ServerConnector@6e2c2e50{HTTP/1.1}{0.0.0.0:4040}
 INFO [2017-07-29 05:53:59,524] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@3c8deca3{/stages/stage/kill,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,526] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@22d13c52{/jobs/job/kill,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,526] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@d6ea43b{/api,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,527] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@34234e0d{/,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,528] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@5b37e3d{/static,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,528] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@7c9a715d{/executors/threadDump/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,530] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@33b148aa{/executors/threadDump,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,531] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@58ed3987{/executors/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,532] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@7791c823{/executors,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,534] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@1b3a8bda{/environment/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,534] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@2e18b5ed{/environment,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,535] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@2830fc7a{/storage/rdd/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,536] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@36bb5f89{/storage/rdd,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,536] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@1ef56c58{/storage/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,536] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@49f9faf3{/storage,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,537] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@32159014{/stages/pool/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,537] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@c949e59{/stages/pool,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,538] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@3d7d54c0{/stages/stage/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,540] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@174d9b4e{/stages/stage,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,540] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@5c7c587f{/stages/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,541] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@1d358da3{/stages,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,541] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@10a757b0{/jobs/job/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,541] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@3deec29c{/jobs/job,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,542] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@a797e24{/jobs/json,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,543] ({Thread-43} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@27a54740{/jobs,null,UNAVAILABLE}
 INFO [2017-07-29 05:53:59,546] ({Thread-43} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://172.17.0.2:4040
 INFO [2017-07-29 05:53:59,573] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2017-07-29 05:53:59,583] ({Thread-43} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2017-07-29 05:53:59,584] ({Thread-43} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2017-07-29 05:53:59,586] ({Thread-43} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2017-07-29 05:53:59,590] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2017-07-29 05:53:59,591] ({Thread-43} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2017-07-29 05:54:01,724] ({Thread-3} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2017-07-29 05:54:01,727] ({Thread-3} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-9bd4517c-1e58-43c0-8640-37cf750c10ce
 INFO [2017-07-29 05:54:01,728] ({Thread-3} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-a36aff49-46dd-4ca1-8897-8f712f0e7762
